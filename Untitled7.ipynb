{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/N5Rv7aMST9EoJPcqSTMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs53/EPIJudge/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\n",
        "from dataset import get_examples, GSMDataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import GPT2Config, AdamW\n",
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    train_examples = get_examples(\"train\")\n",
        "    train_dset = GSMDataset(tokenizer, train_examples)\n",
        "\n",
        " ## device = th.device(\"cuda\")\n",
        "    device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "    config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loader = DataLoader(train_dset, batch_size=16, shuffle=True)\n",
        "    optim = AdamW(model.parameters(), lr=1e-5)\n",
        "    num_epochs = 20\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps=int(0.1 * num_training_steps)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optim,\n",
        "\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "    pbar = tqdm(range(num_training_steps))\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in train_loader:\n",
        "            optim.zero_grad()\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch, labels=batch[\"input_ids\"])\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            lr_scheduler.step()\n",
        "            pbar.update(1)\n",
        "            pbar.set_description(f\"train_loss: {loss.item():.5f}\")\n",
        "\n",
        "    model.save_pretrained(\"model_ckpts/\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "QpyxQTREyHDd",
        "outputId": "9a5b26b7-619e-4194-d4e9-4f694abab1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-221fdf904f23>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGSMDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = '0'\n"
      ],
      "metadata": {
        "id": "gHevo2YA2EiE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}